{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py, os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_h5_files(path1, path2, output_path):\n",
    "    # Open both input files and create output file\n",
    "    with h5py.File(path1, 'r') as hf1, h5py.File(path2, 'r') as hf2, h5py.File(output_path, 'w') as hf_out:\n",
    "        # Assuming both files have same number of graphs\n",
    "        num_graphs = len(hf2.keys())\n",
    "        \n",
    "        # Process each graph\n",
    "        for graph_idx in range(num_graphs):\n",
    "            graph_key = f'graph_{graph_idx}'\n",
    "            graph1 = hf1[graph_key]\n",
    "            graph2 = hf2[graph_key]\n",
    "            \n",
    "            # Create group in output file\n",
    "            graph_out = hf_out.create_group(graph_key)\n",
    "            \n",
    "            # Combine position data (concatenate on dim 1)\n",
    "            pos1 = graph1['liq_position'][:]\n",
    "            pos2 = graph2['liq_position'][:]\n",
    "            combined_pos = np.concatenate([pos1, pos2], axis=1)\n",
    "            graph_out.create_dataset('liq_position', data=combined_pos)\n",
    "            \n",
    "            # Combine mesh_pose data (concatenate on dim 0)\n",
    "            mesh_pose1 = graph1['mesh_pose'][:]\n",
    "            mesh_pose2 = graph2['mesh_pose'][:]\n",
    "            combined_mesh_pose = np.concatenate([mesh_pose1, mesh_pose2], axis=0)\n",
    "            graph_out.create_dataset('mesh_pose', data=combined_mesh_pose)\n",
    "            \n",
    "            # Combine mesh_position data (concatenate on dim 1)\n",
    "            mesh_pos1 = graph1['mesh_position'][:]\n",
    "            mesh_pos2 = graph2['mesh_position'][:]\n",
    "            combined_mesh_pos = np.concatenate([mesh_pos1, mesh_pos2], axis=1)\n",
    "            graph_out.create_dataset('mesh_position', data=combined_mesh_pos)\n",
    "            \n",
    "            # Combine particle_types data (concatenate on dim 0)\n",
    "            ptypes1 = graph1['particle_types'][:]\n",
    "            ptypes2 = graph2['particle_types'][:]\n",
    "            combined_ptypes = np.concatenate([ptypes1, ptypes2], axis=0)\n",
    "            graph_out.create_dataset('particle_types', data=combined_ptypes)\n",
    "\n",
    "# Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path1 = '/home/niteesh/Documents/source_codes/learning_to_simulate_pouring/datasets/Pouring_sdf_transRotate_new/test/simulation_0.h5'\n",
    "# path2 = '/home/niteesh/Documents/source_codes/learning_to_simulate_pouring/datasets/Pouring_sdf_newTest/test/simulation_0.h5'\n",
    "# path3 = '/home/niteesh/Documents/source_codes/learning_to_simulate_pouring/datasets/Pouring_combined/test/simulation_1.h5'\n",
    "\n",
    "path1 = '/home/niteesh/Documents/source_codes/PouringSim/data/simulation_output/simout_1312_lessPt/Pouring_sdf_transRotate_new2/test/simulation_2.h5'\n",
    "path2 = '/home/niteesh/Documents/source_codes/PouringSim/data/simulation_output/simout_MartiniBottle_2701_lessPt/Pouring_sdf_MartiniBottle_2701_lessPt1/test/simulation_0.h5'\n",
    "path3 = '/home/niteesh/Documents/source_codes/learning_to_simulate_pouring/datasets/Pouring_combined/test/simulation_2.h5'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "415\n",
      "liq_position (7, 1047, 3)\n",
      "mesh_pose (3, 7, 6)\n",
      "mesh_position (7, 1271, 3)\n",
      "particle_types (1271,)\n"
     ]
    }
   ],
   "source": [
    "with h5py.File(path1, 'r') as hf:\n",
    "    #iterate over the each graph index in order\n",
    "    num_steps = len(hf.keys())\n",
    "    print(num_steps)\n",
    "\n",
    "    #first get init positions from the first graph\n",
    "    graph_key = f'graph_{0}'\n",
    "    graph_data = hf[graph_key]\n",
    "    for i,v in graph_data.items():\n",
    "        print(i, v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "415\n",
      "liq_position (7, 2094, 3)\n",
      "mesh_pose (6, 7, 6)\n",
      "mesh_position (7, 2479, 3)\n",
      "particle_types (2479,)\n"
     ]
    }
   ],
   "source": [
    "combine_h5_files(path1, path2, path3)\n",
    "\n",
    "with h5py.File(path3, 'r') as hf:\n",
    "    #iterate over the each graph index in order\n",
    "    num_steps = len(hf.keys())\n",
    "    print(num_steps)\n",
    "\n",
    "    #first get init positions from the first graph\n",
    "    graph_key = f'graph_{0}'\n",
    "    graph_data = hf[graph_key]\n",
    "    for i,v in graph_data.items():\n",
    "        print(i, v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, os\n",
    "import numpy as np\n",
    "import jax.numpy as jnp\n",
    "\n",
    "from reading_utils_torch import MultiGraphDataset_torch, SingleDatasetBatchSampler\n",
    "import jax.numpy as jnp\n",
    "import jraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = ['datasets/Pouring_sdf_MartiniBottle_2701_lessPt1/train', 'datasets/Pouring_sdf_newTest/train', ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _read_metadata(data_path):\n",
    "  with open(os.path.join(data_path, 'metadata.json'), 'rt') as fp:\n",
    "    return json.loads(fp.read())\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_n_liq_node_dset, _max_edges_l_dset, _max_edges_m_dset = 0,0,0\n",
    "mesh_pt_type_lists = []\n",
    "batch_size = 5\n",
    "for path in data_path:\n",
    "    metadata = _read_metadata(f'{path}/../')\n",
    "    \n",
    "    collision_mesh_info_list = metadata[\"collision_mesh\"] \n",
    "    mesh_pt_type_list = [ z[1] for z in collision_mesh_info_list] #mesh pt type for handling in v_o\n",
    "    mesh_pt_type_lists.append(mesh_pt_type_list)\n",
    "\n",
    "    _max_n_liq_node_per_graph = int(metadata[\"max_n_liq_node\"]) #  can be read from position as well.. ignore for now\n",
    "    _max_edges_l_per_graph =int( metadata[\"max_n_edge_l\"])\n",
    "    _max_edges_m_per_graph =int( metadata[\"max_n_edge_m\"])\n",
    "\n",
    "    max_n_liq_node_dset = max(max_n_liq_node_dset, _max_n_liq_node_per_graph)\n",
    "    _max_edges_l_dset = max(_max_edges_l_dset, _max_edges_l_per_graph)\n",
    "    _max_edges_m_dset = max(_max_edges_m_dset, _max_edges_m_per_graph)\n",
    "\n",
    "    connectivity_radius = metadata[\"default_connectivity_radius\"] # HAS TO BE SAME FOR ALL DATASETS!!\n",
    "\n",
    "#max for all datasets\n",
    "max_nodes_edges_info = [batch_size,max_n_liq_node_dset, _max_edges_l_dset, _max_edges_m_dset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 1, 0], [0, 1, 0]]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mesh_pt_type_lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MultiGraphDataset_torch(data_path, mesh_pt_type_lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "datas = []\n",
    "for u, d in enumerate(dataset):\n",
    "    datas.append(d[0])\n",
    "    if u==batch_size-1:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "liq_position (1047, 6, 3)\n",
      "mesh_position (1, 1208, 6, 3)\n",
      "mesh_pose (1, 3, 6, 6)\n",
      "particle_type (1208,)\n",
      "particle_type_obj (3,)\n",
      "target (1047, 3)\n"
     ]
    }
   ],
   "source": [
    "for k,v in d[0].nodes.items():\n",
    "    print(k, v.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "batched_graphs = jraph.batch(datas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "liq_position (5235, 6, 3)\n",
      "mesh_pose (5, 3, 6, 6)\n",
      "mesh_position (5, 1208, 6, 3)\n",
      "particle_type (6040,)\n",
      "particle_type_obj (15,)\n",
      "target (5235, 3)\n",
      "[1047 1047 1047 1047 1047]\n"
     ]
    }
   ],
   "source": [
    "for k,v in batched_graphs.nodes.items():\n",
    "    print(k, v.shape)\n",
    "print(batched_graphs.n_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_graphs = jraph.pad_with_graphs(\n",
    "        batched_graphs,\n",
    "        n_node=1047 * len(datas) + 1,\n",
    "        n_edge=2e4 * len(datas),\n",
    "        n_graph=len(datas) + 1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "liq_position (5236, 6, 3)\n",
      "mesh_pose (6, 3, 6, 6)\n",
      "mesh_position (6, 1208, 6, 3)\n",
      "particle_type (6041,)\n",
      "particle_type_obj (16,)\n",
      "target (5236, 3)\n"
     ]
    }
   ],
   "source": [
    "for k,v in padded_graphs.nodes.items():\n",
    "    print(k, v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Array([1047, 1047, 1047, 1047, 1047], dtype=int32),\n",
       " array([1047, 1047, 1047, 1047, 1047,    1], dtype=int32))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batched_graphs.n_node, padded_graphs.n_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gnn_jax",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
